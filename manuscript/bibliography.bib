% Encoding: UTF-8


@article{akshay2020,
 author = {V. Akshay and H. Philathong and M.{\hspace{0.167em}}E.{\hspace{0.167em}}S. Morales and J.{\hspace{0.167em}}D. Biamonte},
 optdoi = {10.1103/physrevlett.124.090504},
 journal = {Physical Review Letters},
 month = {mar},
 number = {9},
 publisher = {American Physical Society ({APS})},
 title = {Reachability Deficits in Quantum Approximate Optimization},
 volume = {124},
 pages = {090504},
 year = {2020}
}

@Article{Liu2022,
  author    = {Zidu Liu and Pei-Xin Shen and Weikang Li and L-M Duan and Dong-Ling Deng},
  journal   = {Quantum Science and Technology},
  title     = {Quantum capsule networks},
  year      = {2022},
  month     = {dec},
  number    = {1},
  pages     = {015016},
  volume    = {8},
  doi       = {10.1088/2058-9565/aca55d},
  publisher = {{IOP} Publishing},
}

@Article{Heese2022,
  author    = {Raoul Heese and Patricia Bickert and Astrid Elisa Niederle},
  journal   = {Quantum},
  title     = {Representation of binary classification trees with binary features by quantum circuits},
  year      = {2022},
  month     = {mar},
  pages     = {676},
  volume    = {6},
  doi       = {10.22331/q-2022-03-30-676},
  publisher = {Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
}


@Article{Viteritti2023,
  author    = {Luciano Loris Viteritti and Riccardo Rende and Federico Becca},
  journal   = {Physical Review Letters},
  title     = {Transformer Variational Wave Functions for Frustrated Quantum Spin Systems},
  year      = {2023},
  month     = {jun},
  number    = {23},
  pages     = {236401},
  volume    = {130},
  doi       = {10.1103/physrevlett.130.236401},
  publisher = {American Physical Society ({APS})},
}

@Article{Benedetti2019,
  author    = {Marcello Benedetti and Erika Lloyd and Stefan Sack and Mattia Fiorentini},
  journal   = {Quantum Science and Technology},
  title     = {Parameterized quantum circuits as machine learning models},
  year      = {2019},
  month     = {nov},
  number    = {4},
  pages     = {043001},
  volume    = {4},
  doi       = {10.1088/2058-9565/ab4eb5},
  publisher = {{IOP} Publishing},
}

@Article{Sajjan2022,
  author    = {Manas Sajjan and Junxu Li and Raja Selvarajan and Shree Hari Sureshbabu and Sumit Suresh Kale and Rishabh Gupta and Vinit Singh and Sabre Kais},
  journal   = {Chemical Society Reviews},
  title     = {Quantum machine learning for chemistry and physics},
  year      = {2022},
  number    = {15},
  pages     = {6475--6573},
  volume    = {51},
  doi       = {10.1039/d2cs00203e},
  publisher = {Royal Society of Chemistry ({RSC})},
}


@Article{Cerezo2022,
  author    = {M. Cerezo and Guillaume Verdon and Hsin-Yuan Huang and Lukasz Cincio and Patrick J. Coles},
  journal   = {Nature Computational Science},
  title     = {Challenges and opportunities in quantum machine learning},
  year      = {2022},
  month     = {sep},
  number    = {9},
  pages     = {567--576},
  volume    = {2},
  doi       = {10.1038/s43588-022-00311-3},
  publisher = {Springer Science and Business Media {LLC}},
}


@Article{Bharti2022,
  author    = {Kishor Bharti and Alba Cervera-Lierta and Thi Ha Kyaw and Tobias Haug and Sumner Alperin-Lea and Abhinav Anand and Matthias Degroote and Hermanni Heimonen and Jakob S. Kottmann and Tim Menke and Wai-Keong Mok and Sukin Sim and Leong-Chuan Kwek and Al{\'{a}}n Aspuru-Guzik},
  journal   = {Reviews of Modern Physics},
  title     = {Noisy intermediate-scale quantum algorithms},
  year      = {2022},
  month     = {feb},
  number    = {1},
  pages     = {015004},
  volume    = {94},
  doi       = {10.1103/revmodphys.94.015004},
  publisher = {American Physical Society ({APS})},
}


@Article{Cerezo2021,
  author    = {M. Cerezo and Andrew Arrasmith and Ryan Babbush and Simon C. Benjamin and Suguru Endo and Keisuke Fujii and Jarrod R. McClean and Kosuke Mitarai and Xiao Yuan and Lukasz Cincio and Patrick J. Coles},
  journal   = {Nature Reviews Physics},
  title     = {Variational quantum algorithms},
  year      = {2021},
  month     = {aug},
  number    = {9},
  pages     = {625--644},
  volume    = {3},
  doi       = {10.1038/s42254-021-00348-9},
  publisher = {Springer Science and Business Media {LLC}},
}


@misc{sevilla2022compute,
      title={Compute Trends Across Three Eras of Machine Learning}, 
      author={Jaime Sevilla and Lennart Heim and Anson Ho and Tamay Besiroglu and Marius Hobbhahn and Pablo Villalobos},
      year={2022},
      eprint={2202.05924},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{allcock2018,
 author = {{Allcock}, Jonathan and {Hsieh}, Chang-Yu and {Kerenidis}, Iordanis and {Zhang}, Shengyu},
 journal = {arXiv:1812.03089},
 title = {Quantum algorithms for feedforward neural networks},
 year = {2018}
}

% no volume
@article{appiah2009,
 author = {Kofi Appiah and Andrew Hunter and  Hongying Meng and  Shigang Yue and Mervyn Hobden and Nigel Priestley and Peter Hobden and Cy Pettit},
 journal = {2009 International Joint Conference on Neural Networks},
 optdoi = {10.1109/ijcnn.2009.5179001},
 month = {jun},
 publisher = {{IEEE}},
 title = {A binary Self-Organizing Map and its {FPGA} implementation},
 opturl = {https://doi.org/10.1109%2Fijcnn.2009.5179001},
 pages = {164--171},
 year = {2009}
}

@article{arute2020,
 author = {Frank Arute and Kunal Arya and Ryan Babbush and Dave Bacon and Joseph C. Bardin and Rami Barends and Sergio Boixo and Michael Broughton and Bob B. Buckley and David A. Buell and Brian Burkett and Nicholas Bushnell and Yu Chen and Zijun Chen and Ben Chiaro and Roberto Collins and William Courtney and Sean Demura and Andrew Dunsworth and Edward Farhi and Austin Fowler and Brooks Foxen and Craig Gidney and Marissa Giustina and Rob Graff and Steve Habegger and Matthew P. Harrigan and Alan Ho and Sabrina Hong and Trent Huang and L. B. Ioffe and Sergei V. Isakov and Evan Jeffrey and Zhang Jiang and Cody Jones and Dvir Kafri and Kostyantyn Kechedzhi and Julian Kelly and Seon Kim and Paul V. Klimov and Alexander N. Korotkov and Fedor Kostritsa and David Landhuis and Pavel Laptev and Mike Lindmark and Martin Leib and Erik Lucero and Orion Martin and John M. Martinis and Jarrod R. McClean and Matt McEwen and Anthony Megrant and Xiao Mi and Masoud Mohseni and Wojciech Mruczkiewicz and Josh Mutus and Ofer Naaman and Matthew Neeley and Charles Neill and Florian Neukart and Hartmut Neven and Murphy Yuezhen Niu and Thomas E. O'Brien and Bryan O'Gorman and Eric Ostby and Andre Petukhov and Harald Putterman and Chris Quintana and Pedram Roushan and Nicholas C. Rubin and Daniel Sank and Kevin J. Satzinger and Andrea Skolik and Vadim Smelyanskiy and Doug Strain and Michael Streif and Kevin J. Sung and Marco Szalay and Amit Vainsencher and Theodore White and Z. Jamie Yao and Ping Yeh and Adam Zalcman and Leo Zhou},
 journal = {arXiv: 2004.04197},
 title = {Quantum Approximate Optimization of Non-Planar Graph Problems on a Planar Superconducting Processor},
 year = {2020}
}

@article{aspuru-guzik2005,
 author = {A. Aspuru-Guzik},
 optdoi = {10.1126/science.1113479},
 journal = {Science},
 month = {sep},
 number = {5741},
 pages = {1704--1707},
 publisher = {American Association for the Advancement of Science ({AAAS})},
 title = {Simulated Quantum Computation of Molecular Energies},
 volume = {309},
 year = {2005}
}

@article{biamonte2017,
 author = {Jacob Biamonte and Peter Wittek and Nicola Pancotti and Patrick Rebentrost and Nathan Wiebe and Seth Lloyd},
 optdoi = {10.1038/nature23474},
 journal = {Nature},
 month = {sep},
 number = {7671},
 pages = {195--202},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Quantum machine learning},
 volume = {549},
 year = {2017}
}

@article{bio0,
 abstract = {Circular RNAs (circRNAs) are ubiquitous endogenous RNA found in various organisms that can regulate gene expression in eukaryotes. However, little is known about potential roles for circRNAs in muscle development. We analyzed circRNA sequencing data of bovine skeletal muscle tissue and found differential expression of circTitin (circTTN) in fetal and adult bovine muscle tissue. We then further studied the role of circTTN in bovine muscle development. Overexpression and inhibition of circTTN together elicited its promoting roles in proliferation and differentiation of bovine primary myoblasts. Mechanistically, circTTN showed interaction with miR-432 by luciferase screening and RNA immunoprecipitation (RIP) assays. Additionally, miR-432 is a regulator of insulin-like growth factor 2 (IGF2), as indicated by luciferase activity, quantitative real-time PCR, and western blotting assays. Increased miR-432 expression inhibited the expression of IGF2, but this effect was remitted by circTTN. Conclusively, our results showed that circTTN promoted proliferation and differentiation of bovine primary myoblasts via competitively combining with miR-432 to activate the IGF2/phosphatidylinositol 3-kinase (PI3K)/AKT signaling pathway.},
 author = {Xiaogang Wang and Xiukai Cao and Dong Dong and Xuemei Shen and Jie Cheng and Rui Jiang and Zhaoxin Yang and Shujun Peng and Yongzhen Huang and Xianyong Lan and Ibrahim Elsaeid Elnour and Chuzhao Lei and Hong Chen},
 optdoi = {https://doi.org/10.1016/j.omtn.2019.10.019},
 issn = {2162-2531},
 journal = {Molecular Therapy - Nucleic Acids},
 keywords = {bovine, circRNA, miRNA,  pathway, myoblast},
 pages = {966 - 980},
 title = {Circular RNA TTN Acts As a miR-432 Sponge to Facilitate Proliferation and Differentiation of Myoblasts via the IGF2/PI3K/AKT Signaling Pathway},
 opturl = {http://www.sciencedirect.com/science/article/pii/S2162253119303294},
 volume = {18},
 year = {2019}
}

@article{bio1,
 abstract = {Eimeria tenella, an obligate intracellular parasite, can actively invade the cecal epithelial cells of chickens and cause severe enteric disease. Eukaryotic elongation factor 2 (eEF2) plays a major role in protein synthesis and cell survival. This study aims to explore the exact mechanisms underlying diclazuril inhibition in second-generation merozoites of E. tenella. The eEF2 cDNA of the second-generation merozoites of E. tenella (EtEF2) was cloned by reverse transcriptase polymerase chain reaction and rapid amplification of cDNA ends. Diclazuril-induced expression profiles of EtEF2 were also analyzed. The cloned full-length cDNA (2893 bp) of the EtEF2 nucleotide sequence encompassed a 2499 bp open reading frame (ORF) that encoded a polypeptide of 832 residues with an estimated molecular mass of 93.12 kDa and a theoretical isoelectric point of 5.99. The EtEF2 nucleotide sequence was submitted to the GenBank database with the accession number KF188423. The EtEF2 protein sequence shared 99 \% homology with the eEF2 sequence of Toxoplasma gondii (GenBank XP_002367778.1). The GTPase activity domain and ADP-ribosylation domain were conserved signature sequences of the eEF2 gene family. The changes in the transcriptional and translational levels of EtEF2 were detected through quantitative real-time PCR and Western blot analyses. The mRNA expression level of EtEF2 was 2.706 fold increases and the protein level of EtEF2 was increased 67.31 \% under diclazuril treatment. In addition, the localization of EtEF2 was investigated through immunofluorescence assay. Experimental results demonstrated that EtEF2 was distributed primarily in the cytoplasm of second-generation merozoites, and its fluorescence intensity was enhanced after diclazuril treatment. These findings indicated that EtEF2 may have an important role in understanding the signaling mechanism underlying the anticoccidial action of diclazuril and could be a promising target for novel drug exploration.},
 author = {Bian Zhou and Liu-shu Jia and Hong-wei Guo and Hai-yan Ding and Jing-yun Yang and Hong-wei Wang},
 optdoi = {10.1016/j.vetpar.2019.108991},
 journal = {Veterinary Parasitology},
 keywords = {, Diclazuril, Eukaryotic elongation factor 2, Second-generation merozoites},
 month = {dec},
 pages = {108991},
 publisher = {Elsevier {BV}},
 title = {Eukaryotic elongation factor 2 is involved in the anticoccidial action of diclazuril in the second-generation merozoites of Eimeria tenella},
 opturl = {https://doi.org/10.1016%2Fj.vetpar.2019.108991},
 volume = {276},
 year = {2019}
}

@article{bio2,
 abstract = {Abstract Background The negative signal provided by some co-inhibitory factors such as programmed cell death-1 (PD-1) has been associated with chronic hepatitis B (CHB) infection induced-T cell exhaustion, although the correlation of CpG methylation of the Pdcd1 gene with PD-1 expression and medical laboratory indicators in CHB infection has not yet been elucidated. Methods Blood samples from 20 CHB infection patients and 20 spontaneous clearance (SC) patients were collected. Percentages of PD-1-positive CD8+ T cells were analyzed by flow cytometry. The percentage of CpG methylation at the Pdcd1 locus was analyzed by bisulfite sequencing. Student's t test, Pearson and Spearman's correlation, and Mann–Whitney tests were used in the statistical analysis. Results Percentages of PD-1-positive CD8+ T cells in peripheral blood T cells were significantly higher in CHB patients than in the SC group (p < 0.001). The methylation level of Pdcd1 was significantly lower in CHB patients (p < 0.001) and the methylation level of Pdcd1 was negatively correlated with PD-1 expression level in CD8+ T cells (p < 0.001) and hepatitis-B surface antigen (HBsAg) (p < 0.001). Conclusions The results of the present study suggest that Pdcd1 methylation is correlated with PD-1 expression on CD8+ T cells and correlated with HBsAg and alanine aminotransferase. The results may provide new ideas regarding anti-PD-1 inhibitors, and epigenetic regulators such as demethylation inhibitors could represent more successful therapeutic strategies in hepatitis B infection patients.},
 author = {Lin Jiao and Jie Chen and Xiaojuan Wu and Bei Cai and Zhenzhen Su and Lanlan Wang},
 optdoi = {10.1002/jgm.3148},
 journal = {The Journal of Gene Medicine},
 month = {jan},
 number = {2},
 publisher = {Wiley},
 title = {Correlation of {CpG} methylation of the Pdcd1 gene
with {PD}-1 expression on {CD}8 +
T cells and medical laboratory indicators in chronic hepatitis B infection},
 opturl = {https://doi.org/10.1002%2Fjgm.3148},
 volume = {22},
 pages = {e3148},
 year = {2020}
}

@article{bondarenko2019,
 author = {Dmytro Bondarenko and Polina Feldmann},
 journal = {arXiv: 1910.09169},
 title = {Quantum autoencoders to denoise quantum data},
 year = {2019}
}

@article{broughton2020,
 author = {Michael Broughton and Guillaume Verdon and Trevor McCourt and Antonio J. Martinez and Jae Hyeon Yoo and Sergei V. Isakov and Philip Massey and Murphy Yuezhen Niu and Ramin Halavati and Evan Peters and Martin Leib and Andrea Skolik and Michael Streif and David Von Dollen and Jarrod R. McClean and Sergio Boixo and Dave Bacon and Alan K. Ho and Hartmut Neven and Masoud Mohseni},
 journal = {arXiv: 2003.02989},
 title = {TensorFlow Quantum: A Software Framework for Quantum Machine Learning},
 year = {2020}
}

@article{butler2018,
 abstract = {Here we summarize recent progress in machine learning for the chemical sciences. We outline machine-learning techniques that are suitable for addressing research questions in this domain, as well as future directions for the field. We envisage a future in which the design, synthesis, characterization and application of molecules and materials is accelerated by artificial intelligence.},
 author = {Butler, Keith T.
and Davies, Daniel W.
and Cartwright, Hugh
and Isayev, Olexandr
and Walsh, Aron},
 optdoi = {10.1038/s41586-018-0337-2},
 issn = {1476-4687},
 journal = {Nature},
 number = {7715},
 pages = {547-555},
 title = {Machine learning for molecular and materials science},
 opturl = {https://doi.org/10.1038/s41586-018-0337-2},
 volume = {559},
 year = {2018}
}

@article{byrnes2013,
 author = {Tim Byrnes and Shinsuke Koyama and Kai Yan and Yoshihisa Yamamoto},
 optdoi = {10.1038/srep02531},
 journal = {Scientific Reports},
 month = {aug},
 number = {1},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Neural networks using two-component Bose-Einstein condensates},
 volume = {3},
 pages = {2531},
 year = {2013}
}

@article{carleo2019,
 author = {Giuseppe Carleo and Ignacio Cirac and Kyle Cranmer and Laurent Daudet and Maria Schuld and Naftali Tishby and Leslie Vogt-Maranto and Lenka Zdeborov{\'{a}}},
 optdoi = {10.1103/revmodphys.91.045002},
 journal = {Reviews of Modern Physics},
 month = {dec},
 number = {4},
 publisher = {American Physical Society ({APS})},
 title = {Machine learning and the physical sciences},
 volume = {91},
 pages = {045002},
 year = {2019}
}

@article{chea2016,
 author = {Ratha Chea and Gaël Grenouillet and Sovan Lek},
 optdoi = {10.1371/journal.pone.0145527},
 editor = {Chon-Lin Lee},
 journal = {{PLOS} {ONE}},
 month = {jan},
 number = {1},
 pages = {e0145527},
 publisher = {Public Library of Science ({PLoS})},
 title = {Evidence of Water Quality Degradation in Lower Mekong Basin Revealed by Self-Organizing Map},
 volume = {11},
 year = {2016}
}

@article{cherny2019,
 author = {Valentin V. Cherny and Tim Byrnes and Alexey N. Pyrkov},
 optdoi = {10.1002/qute.201800087},
 journal = {Advanced Quantum Technologies},
 month = {feb},
 number = {7-8},
 pages = {1800087},
 publisher = {Wiley},
 title = {Nontrivial Attractors of the Perturbed Nonlinear Schrödinger Equation: Applications to Associative Memory and Pattern Recognition},
 volume = {2},
 year = {2019}
}

@article{childs2017,
 author = {Andrew M. Childs and Robin Kothari and Rolando D. Somma},
 optdoi = {10.1137/16m1087072},
 journal = {{SIAM} Journal on Computing},
 month = {jan},
 number = {6},
 pages = {1920--1950},
 publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
 title = {Quantum Algorithm for Systems of Linear Equations with Exponentially Improved Dependence on Precision},
 volume = {46},
 year = {2017}
}

@article{cong2019,
 author = {Iris Cong and Soonwon Choi and Mikhail D. Lukin},
 optdoi = {10.1038/s41567-019-0648-8},
 journal = {Nature Physics},
 month = {aug},
 number = {12},
 pages = {1273--1278},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Quantum convolutional neural networks},
 volume = {15},
 year = {2019}
}

@article{corsello2017,
 author = {Steven M Corsello and Joshua A Bittker and Zihan Liu and Joshua Gould and Patrick McCarren and Jodi E Hirschman and Stephen E Johnston and Anita Vrcic and Bang Wong and Mariya Khan and Jacob Asiedu and Rajiv Narayan and Christopher C Mader and Aravind Subramanian and Todd R Golub},
 optdoi = {10.1038/nm.4306},
 journal = {Nature Medicine},
 month = {apr},
 number = {4},
 pages = {405--408},
 publisher = {Springer Science and Business Media {LLC}},
 title = {The Drug Repurposing Hub: a next-generation drug library and information resource},
 volume = {23},
 year = {2017}
}

@article{doszkocs1990,
 abstract = {},
 author = {Doszkocs, T. E and  Reggia, J and Lin, X},
 journal = {ARIST},
 key = {},
 note = {},
 number = {},
 pages = {209-260.},
 title = {Connectionist models and information retrieval. Annual Review of Information Science and Technology},
 opturl = {},
 volume = {25},
 year = {1990}
}

@article{dunjko2016,
 abstract = {The emerging field of quantum machine learning has the potential to substantially aid in the problems and scope of artificial intelligence. This is only enhanced by recent successes in the field of classical machine learning. In this work we propose an approach for the systematic treatment of machine learning, from the perspective of quantum information. Our approach is general and covers all three main branches of machine learning: supervised, unsupervised, and reinforcement learning. While quantum improvements in supervised and unsupervised learning have been reported, reinforcement learning has received much less attention. Within our approach, we tackle the problem of quantum enhancements in reinforcement learning as well, and propose a systematic scheme for providing improvements. As an example, we show that quadratic improvements in learning efficiency, and exponential improvements in performance over limited time periods, can be obtained for a broad class of learning problems.},
 author = {Dunjko, Vedran and Taylor, Jacob M. and Briegel, Hans J.},
 optdoi = {10.1103/PhysRevLett.117.130501},
 issue = {13},
 journal = {Phys. Rev. Lett.},
 month = {Sep},
 numpages = {6},
 pages = {130501},
 publisher = {American Physical Society},
 title = {Quantum-Enhanced Machine Learning},
 opturl = {https://link.aps.org/doi/10.1103/PhysRevLett.117.130501},
 volume = {117},
 year = {2016}
}

@article{dunjko2017,
 author = {Vedran Dunjko and Jacob M. Taylor and Hans J. Briegel},
 journal = {2017 {IEEE} International Conference on Systems, Man, and Cybernetics ({SMC})},
 optdoi = {10.1109/smc.2017.8122616},
 month = {oct},
 publisher = {{IEEE}},
 title = {Advances in quantum reinforcement learning},
 pages = {282-287},
 year = {2017}
}

@article{dunjko2018,
 author = {Vedran Dunjko and Hans J Briegel},
 optdoi = {10.1088/1361-6633/aab406},
 journal = {Reports on Progress in Physics},
 month = {jun},
 number = {7},
 pages = {074001},
 publisher = {{IOP} Publishing},
 title = {Machine learning {\&} artificial intelligence in the quantum domain: a review of recent progress},
 volume = {81},
 year = {2018}
}

@article{esteva2019,
 abstract = {Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.},
 author = {Esteva, Andre
and Robicquet, Alexandre
and Ramsundar, Bharath
and Kuleshov, Volodymyr
and DePristo, Mark
and Chou, Katherine
and Cui, Claire
and Corrado, Greg
and Thrun, Sebastian
and Dean, Jeff},
 journal = {Nature Medicine},
 key = {},
 note = {},
 number = {1},
 pages = {24-29},
 title = {A guide to deep learning in healthcare},
 opturl = {https://doi.org/10.1038/s41591-018-0316-z},
 volume = {25},
 year = {2019}
}

@article{farhi2014,
 author = {Edward Farhi and Jeffrey Goldstone and Sam Gutmann},
 journal = {arXiv: 1411.4028},
 title = {A quantum approximate optimization algorithm},
 year = {2014}
}

@article{farhi2016,
 author = {Edward Farhi and Aram W Harrow},
 journal = {arXiv: 1602.07674},
 title = {Quantum Supremacy through the Quantum Approximate Optimization Algorithm},
 year = {2016}
}

@article{foesel2018,
 author = {Thomas F\"osel and Petru Tighineanu and Talitha Weiss and Florian Marquardt},
 optdoi = {10.1103/physrevx.8.031084},
 journal = {Physical Review X},
 month = {sep},
 number = {3},
 publisher = {American Physical Society ({APS})},
 title = {Reinforcement Learning with Neural Networks for Quantum Feedback},
 volume = {8},
 year = {2018},
 pages = {031084}
}

@article{ghahramani2015,
 abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
 author = {Ghahramani, Zoubin},
 optdoi = {10.1038/nature14541},
 issn = {1476-4687},
 journal = {Nature},
 number = {7553},
 pages = {452-459},
 title = {Probabilistic machine learning and artificial intelligence},
 opturl = {https://doi.org/10.1038/nature14541},
 volume = {521},
 year = {2015}
}

@book{guido1998,
 address = {Reading, Massachusetts},
 author = {Deboeck, Guido and  Kohonen, Teuvo},
 optdoi = {10.1007/978-1-4471-3913-3},
 publisher = {Springer-Verlag London},
 title = {Visual Explorations in Finance},
 year = {1998}
}

@article{harrow2009,
 author = {Aram W. Harrow and Avinatan Hassidim and Seth Lloyd},
 optdoi = {10.1103/physrevlett.103.150502},
 journal = {Physical Review Letters},
 month = {oct},
 number = {15},
 publisher = {American Physical Society ({APS})},
 title = {Quantum Algorithm for Linear Systems of Equations},
 volume = {103},
 pages = {150502},
 year = {2009}
}

@article{huang2019,
 author = {Cupjin Huang and Mario Szegedy and Fang Zhang and Xun Gao and Jianxin Chen and Yaoyun Shi},
 journal = {arXiv: 1909.02559},
 title = {Alibaba Cloud Quantum Development Platform: Applications to Quantum Algorithm Design},
 year = {2019}
}

@misc{ibmq,
 title = {{IBM} {Q}uantum {E}xperience},
 url = {https://www.ibm.com/quantum-computing/}
}

@article{jeswal2019,
 abstract = {Quantum neural network is a useful tool which has seen more development over the years mainly after twentieth century. Like artificial neural network (ANN), a novel, useful and applicable concept has been proposed recently which is known as quantum neural network (QNN). QNN has been developed combining the basics of ANN with quantum computation paradigm which is superior than the traditional ANN. QNN is being used in computer games, function approximation, handling big data etc. Algorithms of QNN are also used in modelling social networks, associative memory devices, and automated control systems etc. Different models of QNN has been proposed by different researchers throughout the world but systematic study of these models have not been done till date. Moreover, application of QNN may also be seen in some of the related research papers. As such, this paper includes different models which have been developed and further the implement of the same in various applications. In order to understand the powerfulness of QNN, few results and reasons are incorporated to show that these new models are more useful and efficient than traditional ANN.},
 author = {Jeswal, S. K.
and Chakraverty, S.},
 optdoi = {10.1007/s11831-018-9269-0},
 issn = {1886-1784},
 journal = {Archives of Computational Methods in Engineering},
 number = {4},
 pages = {793-807},
 title = {Recent Developments and Applications in Quantum Neural Network: A Review},
 opturl = {https://doi.org/10.1007/s11831-018-9269-0},
 volume = {26},
 year = {2019}
}

@article{jiang2017,
 author = {Zhang Jiang and Eleanor G. Rieffel and Zhihui Wang},
 optdoi = {10.1103/physreva.95.062317},
 journal = {Physical Review A},
 month = {jun},
 number = {6},
 publisher = {American Physical Society ({APS})},
 title = {Near-optimal quantum circuit for Grover's unstructured search using a transverse field},
 volume = {95},
 pages = {062317},
 year = {2017}
}

@article{jones2012,
 author = {Felicity C. Jones and and Manfred G. Grabherr and Yingguang Frank Chan and Pamela Russell and Evan Mauceli and Jeremy Johnson and Ross Swofford and Mono Pirun and Michael C. Zody and Simon White and Ewan Birney and Stephen Searle and Jeremy Schmutz and Jane Grimwood and Mark C. Dickson and Richard M. Myers and Craig T. Miller and Brian R. Summers and Anne K. Knecht and Shannon D. Brady and Haili Zhang and Alex A. Pollen and Timothy Howes and Chris Amemiya and Eric S. Lander and Federica Di Palma and Kerstin Lindblad-Toh and David M. Kingsley},
 optdoi = {10.1038/nature10944},
 journal = {Nature},
 month = {apr},
 number = {7392},
 pages = {55--61},
 publisher = {Springer Science and Business Media {LLC}},
 title = {The genomic basis of adaptive evolution in threespine sticklebacks},
 volume = {484},
 year = {2012}
}

@misc{kaggle2014,
 abstract = {},
 author = {},
 url = {https://www.kaggle.com/c/higgs-boson},
 key = {},
 note = {},
 number = {},
 pages = {},
 title = {Kaggle: Higgs boson machine learning challenge.},
 opturl = {},
 volume = {},
 year = {2014}
}

% book?
@inproceedings{kamruzzaman2019,
 author = {Kamruzzaman, Abu
    and Alhwaiti, Yousef
    and Leider, Avery
    and Tappert, Charles C.
 },
 booktitle = {Knowledge Science, Engineering and Management},
 title = {Quantum Deep Learning Neural Networks},
 editor = {Arai, Kohei and Bhatia, Rahul},
 optdoi = {10.1007/978-3-030-12385-7_24},
 month = {feb},
 pages = {299--311},
 publisher = {Springer, Cham},
 year = {2020},
 isbn = {978-3-030-12385-7}
}

@article{kandala2017,
 author = {Abhinav Kandala and Antonio Mezzacapo and Kristan Temme and Maika Takita and Markus Brink and Jerry M. Chow and Jay M. Gambetta},
 optdoi = {10.1038/nature23879},
 journal = {Nature},
 month = {sep},
 number = {7671},
 pages = {242--246},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets},
 volume = {549},
 year = {2017}
}

@article{kerenidis2018,
 author = {{Kerenidis}, Iordanis and {Luongo}, Alessandro},
 journal = {arXiv:1805.08837},
 title = {Quantum classification of the MNIST dataset via Slow Feature Analysis},
 year = {2018}
}

@article{key,
 abstract = {},
 author = {},
 journal = {},
 key = {},
 note = {},
 number = {},
 pages = {},
 title = {},
 opturl = {},
 volume = {},
 year = {}
}

@article{killoran2019,
 author = {Nathan Killoran and Thomas R. Bromley and Juan Miguel Arrazola and Maria Schuld and Nicol{\'{a}}s Quesada and Seth Lloyd},
 journal = {Physical Review Research},
 month = {oct},
 number = {3},
 optdoi = {10.1103/physrevresearch.1.033063},
 publisher = {American Physical Society ({APS})},
 title = {Continuous-variable quantum neural networks},
 volume = {1},
 pages = {033063},
 year = {2019}
}

% inproceedings
@article{kiviluotoa1996,
  author={K. Kiviluoto},
  journal={Proceedings of International Conference on Neural Networks (ICNN'96)},
  title={Topology preservation in self-organizing maps},
  year={1996},
  volume={1},
  number={},
  pages={294-299}
}

@article{kohonen1990,
 abstract = {The self-organized map, an architecture suggested for artificial neural networks, is explained by presenting simulation experiments and practical applications. The self-organizing map has the property of effectively creating spatially organized internal representations of various features of input signals and their abstractions. One result of this is that the self-organization process can discover semantic relationships in sentences. Brain maps, semantic maps, and early work on competitive learning are reviewed. The self-organizing map algorithm (an algorithm which order responses spatially) is reviewed, focusing on best matching cell selection and adaptation of the weight vectors. Suggestions for applying the self-organizing map algorithm, demonstrations of the ordering process, and an example of hierarchical clustering of data are presented. Fine tuning the map by learning vector quantization is addressed. The use of self-organized maps in practical speech recognition and a simulation experiment on semantic mapping are discussed.<>},
 author = {T. {Kohonen}},
 optdoi = {10.1109/5.58325},
 issn = {1558-2256},
 journal = {Proceedings of the IEEE},
 keywords = {learning systems;neural nets;self-adjusting systems;speech recognition;self-organizing map;neural networks;semantic maps;competitive learning;clustering;learning vector;speech recognition;Biological neural networks;Artificial neural networks;Pattern recognition;Process control;Signal processing;Computer networks;Signal processing algorithms;Animals;Organizing;Speech recognition},
 month = {Sep.},
 number = {9},
 pages = {1464-1480},
 title = {The self-organizing map},
 volume = {78},
 year = {1990}
}

@article{kohonen1996,
 author = {T. Kohonen and E. Oja and O. Simula and A. Visa and J. Kangas},
 optdoi = {10.1109/5.537105},
 journal = {Proceedings of the {IEEE}},
 number = {10},
 pages = {1358--1384},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Engineering applications of the self-organizing map},
 volume = {84},
 year = {1996}
}

% inproceedings
@article{kohonen1997,
  author={T. Kohonen},
  journal={Proceedings of International Conference on Neural Networks (ICNN'97)},
  title={Exploration of very large databases by self-organizing maps},
  year={1997},
  volume={1},
  number={},
  pages={PL1-PL6}
}

@article{kourtis2020,
 author = {Kornilios Kourtis and Martino Dazzi and Nikolas Ioannou and Tobias Grosser and Abu Sebastian and Evangelos Eleftheriou},
 journal = {arxiv: 2003.04293},
 title = {Compiling Neural Networks for a Computational Memory Accelerator},
 year = {2020}
}

@article{lanyon2010,
 author = {B. P. Lanyon and J. D. Whitfield and G. G. Gillett and M. E. Goggin and M. P. Almeida and I. Kassal and J. D. Biamonte and M. Mohseni and B. J. Powell and M. Barbieri and A. Aspuru-Guzik and A. G. White},
 optdoi = {10.1038/nchem.483},
 journal = {Nature Chemistry},
 month = {jan},
 number = {2},
 pages = {106--111},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Towards quantum chemistry on a quantum computer},
 volume = {2},
 year = {2010}
}

@article{lecun2015,
 abstract = { Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 journal = {Nature},
 key = {},
 note = {},
 number = {7553},
 pages = {436-444},
 title = {Deep learning},
 opturl = {https://doi.org/10.1038/nature14539},
 volume = {521},
 year = {2015}
}

@article{lewenstein1994,
 author = {M. Lewenstein},
 optdoi = {10.1080/09500349414552331},
 journal = {Journal of Modern Optics},
 month = {dec},
 number = {12},
 pages = {2491--2501},
 publisher = {Informa {UK} Limited},
 title = {Quantum Perceptrons},
 volume = {41},
 year = {1994}
}

@article{li2019,
 author = {{Li}, Tongyang and {Chakrabarti}, Shouvanik and {Wu}, Xiaodi},
 journal = {arXiv:1904.02276},
 title = {Sublinear quantum algorithms for training linear and kernel-based classifiers},
 year = {2019}
}

@article{liu2019,
 author = {Junhua Liu and Kwan Hui Lim and Kristin L. Wood and Wei Huang and Chu Guo and He-Liang Huang},
 journal = {arXiv: 1911.02998},
 title = {Hybrid Quantum-Classical Convolutional Neural Networks},
 year = {2019}
}

@article{lloyd2013,
 author = {Seth Lloyd and Masoud Mohseni and Patrick Rebentrost},
 journal = {arXiv: 1307.0411},
 title = {Quantum algorithms for supervised and unsupervised machine learning},
 year = {2013}
}

@article{lloyd2014,
 author = {Seth Lloyd and Masoud Mohseni and Patrick Rebentrost},
 optdoi = {10.1038/nphys3029},
 journal = {Nature Physics},
 month = {jul},
 number = {9},
 pages = {631--633},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Quantum principal component analysis},
 volume = {10},
 year = {2014}
}

@article{lu2019,
 author = {Sirui Lu and Lu-Ming Duan and Dong-Ling Deng},
 journal = {arXiv: 2001.00030},
 title = {Quantum Adversarial Machine Learning},
 year = {2019}
}

@article{marcus2018,
 author = {Marcus, Gary},
 journal = {arxiv: 1801.00631},
 title = {Deep Learning: A Critical Appraisal},
 year = {2018}
}

@article{mcclean2016,
 author = {Jarrod R McClean and Jonathan Romero and Ryan Babbush and Al{\'{a}}n Aspuru-Guzik},
 optdoi = {10.1088/1367-2630/18/2/023023},
 journal = {New Journal of Physics},
 month = {feb},
 number = {2},
 pages = {023023},
 publisher = {{IOP} Publishing},
 title = {The theory of variational hybrid quantum-classical algorithms},
 volume = {18},
 year = {2016}
}

@book{mctear2016,
 author = {Michael McTear and Zoraida Callejas and David Griol},
 optdoi = {10.1007/978-3-319-32967-3},
 publisher = {Springer International Publishing},
 title = {The Conversational Interface},
 opturl = {https://doi.org/10.1007%2F978-3-319-32967-3},
 year = {2016}
}

@article{med0,
 abstract = {Epigenetic alternations concern heritable yet reversible changes in histone or DNA modifications that regulate gene activity beyond the underlying sequence. Epigenetic dysregulation is often linked to human disease, notably cancer. With the development of various drugs targeting epigenetic regulators, epigenetic-targeted therapy has been applied in the treatment of hematological malignancies and has exhibited viable therapeutic potential for solid tumors in preclinical and clinical trials. In this review, we summarize the aberrant functions of enzymes in DNA methylation, histone acetylation and histone methylation during tumor progression and highlight the development of inhibitors of or drugs targeted at epigenetic enzymes.},
 author = {Cheng, Yuan
and He, Cai
and Wang, Manni
and Ma, Xuelei
and Mo, Fei
and Yang, Shengyong
and Han, Junhong
and Wei, Xiawei},
 optdoi = {10.1038/s41392-019-0095-0},
 issn = {2059-3635},
 journal = {Signal Transduction and Targeted Therapy},
 number = {1},
 pages = {62},
 title = {Targeting epigenetic regulators for cancer therapy: mechanisms and advances in clinical trials},
 opturl = {https://doi.org/10.1038/s41392-019-0095-0},
 volume = {4},
 year = {2019}
}

@article{med1,
 abstract = {Over the past decade, the search for dietary factors on which to base cancer prevention guidelines has led to the rapid expansion of the field of dietary patterns and cancer. Multiple systematic reviews and meta-analyses have reported epidemiological associations between specific cancer types and both data-driven dietary patterns determined by empirical analyses and investigator-defined dietary indexes based on a predetermined set of dietary components. New developments, such as the use of metabolomics to identify objective biomarkers of dietary patterns and novel statistical techniques, could provide further insights into the links between diet and cancer risk. Although animal models of dietary patterns are limited, progress in this area could identify the potential mechanisms underlying the disease-specific associations observed in epidemiological studies. In this Review, we summarize the current state of the field, provide a critical appraisal of new developments and identify priority areas for future research. An underlying theme that emerges is that the effectiveness of different dietary pattern recommendations in reducing risk could depend on the type of cancer or on other risk factors such as family history, sex, age and other lifestyle factors or comorbidities as well as on metabolomic signatures or gut microbiota profiles.},
 author = {Steck, Susan E.
and Murphy, E. Angela},
 issn = {1474-1768},
 journal = {Nature Reviews Cancer},
 optdoi = {10.1038/s41568-019-0227-4},
 title = {Dietary patterns and cancer risk},
 opturl = {https://doi.org/10.1038/s41568-019-0227-4},
 volume = {20},
 pages = {125--138},
 year = {2020}
}

@article{med2,
 abstract = {Epigenetic modulation can affect the characteristics of cancers. Because it is likely to manipulate epigenetic genes, they can be considered as potential targets for cancer treatment. In this comprehensive study, epigenetic drugs are categorized according to anticancer mechanisms and phase of therapy. The relevant articles or databases were searched for epigenetic approaches to cancer therapy. Epigenetic drugs are divided according to their mechanisms and clinical phases that have been approved by the FDA or are undergoing evaluation phases. DNA methylation agents, chromatin remodelers specially HDACs, and noncoding RNAs especially microRNAs are the main epi-drugs for cancer. Despite many challenges, combination therapy using epi-drugs and routine therapies such as chemotherapy in various approaches have exhibited beneficial effects compared with each treatment alone. Cancer stem cell targeting and epigenetic editing have been confirmed as definitive pathways for cancer treatment. This paper reviewed the available epigenetic approaches to cancer therapy.},
 author = {Ghasemi, Sorayya},
 journal = {The Pharmacogenomics Journal},
 optdoi = {10.1038/s41397-019-0138-5},
 volume = {20},
 pages = {1473-1150},
 title = {Cancer's epigenetic drugs: where are they in the cancer medicines?},
 opturl = {https://doi.org/10.1038/s41397-019-0138-5},
 year = {2019}
}

@article{mishra2019,
 author = {Nilima Mishra and Aradh Bisarya and Shubham Kumar and Bikash K. Behera and Sabyasachi Mukhopadhyay and Prasanta K. Panigrahi},
 journal = {arXiv: 1911.00504},
 title = {Cancer Detection Using Quantum Neural Networks: A Demonstration on a Quantum Computer},
 year = {2019}
}

@article{mori2019,
 author = {
	Tomoya Mori
	and Haruka Takaoka
	and Junko Yamane
	and Cantas Alev
	and Wataru Fujibuchi},
 journal = {Scientific Reports},
 month = {aug},
 issue = {12597},
 optdoi = {10.1038/s41598-019-49031-1},
 pages = {12597},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Novel computational model of gastrula morphogenesis to identify spatial discriminator genes by self-organizing map (SOM) clustering},
 volume = {9},
 year = {2019}
}

@article{nautrup2019,
 author = {Hendrik Poulsen Nautrup and Nicolas Delfosse and Vedran Dunjko and Hans J. Briegel and Nicolai Friis},
 optdoi = {10.22331/q-2019-12-16-215},
 journal = {Quantum},
 month = {dec},
 pages = {215},
 publisher = {Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
 title = {Optimizing Quantum Error Correction Codes with Reinforcement Learning},
 volume = {3},
 year = {2019}
}

@article{pagano2019,
 author = {G. Pagano and A. Bapat and P. Becker and K. S. Collins and A. De and P. W. Hess and H. B. Kaplan and A. Kyprianidis and W. L. Tan and C. Baldwin and L. T. Brady and A. Deshpande and F. Liu and S. Jordan and A. V. Gorshkov and C. Monroe},
 journal = {arxiv: 1906.02700},
 title = {Quantum Approximate Optimization of the Long-Range Ising Model with a Trapped-Ion Quantum Simulator},
 year = {2019}
}

@article{paparo2014,
 abstract = {Can quantum mechanics help us build intelligent learning agents? A defining signature of intelligent behavior is the capacity to learn from experience. However, a major bottleneck for agents to learn in real-life situations is the size and complexity of the corresponding task environment. Even in a moderately realistic environment, it may simply take too long to rationally respond to a given situation. If the environment is impatient, allowing only a certain time for a response, an agent may then be unable to cope with the situation and to learn at all. Here, we show that quantum physics can help and provide a quadratic speedup for active learning as a genuine problem of artificial intelligence. This result will be particularly relevant for applications involving complex task environments.},
 author = {Paparo, Giuseppe Davide and Dunjko, Vedran and Makmal, Adi and Martin-Delgado, Miguel Angel and Briegel, Hans J.},
 optdoi = {10.1103/PhysRevX.4.031002},
 issue = {3},
 journal = {Phys. Rev. X},
 month = {Jul},
 numpages = {14},
 pages = {031002},
 publisher = {American Physical Society},
 title = {Quantum Speedup for Active Learning Agents},
 opturl = {https://link.aps.org/doi/10.1103/PhysRevX.4.031002},
 volume = {4},
 year = {2014}
}

@article{peruzzo2014,
 author = {Alberto Peruzzo and Jarrod McClean and Peter Shadbolt and Man-Hong Yung and Xiao-Qi Zhou and Peter J. Love and Al{\'{a}}n Aspuru-Guzik and Jeremy L. O'Brien},
 optdoi = {10.1038/ncomms5213},
 journal = {Nature Communications},
 month = {jul},
 number = {1},
 publisher = {Springer Science and Business Media {LLC}},
 title = {A variational eigenvalue solver on a photonic quantum processor},
 volume = {5},
 pages = {4213},
 year = {2014}
}

@article{purushothaman1997,
 author = {G. Purushothaman and N.B. Karayiannis},
 optdoi = {10.1109/72.572106},
 journal = {{IEEE} Transactions on Neural Networks},
 month = {may},
 number = {3},
 pages = {679--693},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Quantum neural networks ({QNNs}): inherently fuzzy feedforward neural networks},
 volume = {8},
 year = {1997}
}

@Article{pyrkov2019,
  author    = {Alexey N. Pyrkov and Tim Byrnes and Valentin V. Cherny},
  title     = {Solitonic Fixed Point Attractors in the Complex Ginzburg{\textendash}Landau Equation for Associative Memories},
  journal   = {Symmetry},
  year      = {2020},
  volume    = {12},
  number    = {1},
  pages     = {24},
  month     = {dec},
  optdoi       = {10.3390/sym12010024},
  publisher = {{MDPI} {AG}},
}

@misc{qiskit,
 author = {H{\'e}ctor Abraham and AduOffei and Ismail Yunus Akhalwaya and Gadi Aleksandrowicz and Thomas Alexander and Gadi Alexandrowics and Eli Arbel and Abraham Asfaw and Carlos Azaustre and AzizNgoueya and Panagiotis Barkoutsos and George Barron and Luciano Bello and Yael Ben-Haim and Daniel Bevenius and Lev S. Bishop and Sorin Bolos and Samuel Bosch and Sergey Bravyi and David Bucher and Artemiy Burov and Fran Cabrera and Padraic Calpin and Lauren Capelluto and Jorge Carballo and Gin{\'e}s Carrascal and Adrian Chen and Chun-Fu Chen and Richard Chen and Jerry M. Chow and Christian Claus and Christian Clauss and Abigail J. Cross and Andrew W. Cross and Simon Cross and Juan Cruz-Benito and Chris Culver and Antonio D. C{\'o}rcoles-Gonzales and Sean Dague and Tareq El Dandachi and Matthieu Dartiailh and DavideFrr and Abd{\'o}n Rodr{\'\i}guez Davila and Anton Dekusar and Delton Ding and Jun optDoi and Eric Drechsler and Drew and Eugene Dumitrescu and Karel Dumon and Ivan Duran and Kareem EL-Safty and Eric Eastman and Pieter Eendebak and Daniel Egger and Mark Everitt and Paco Mart{\'\i}n Fern{\'a}ndez and Axel Hern{\'a}ndez Ferrera and Albert Frisch and Andreas Fuhrer and MELVIN GEORGE and Julien Gacon and Gadi and Borja Godoy Gago and Claudio Gambella and Jay M. Gambetta and Adhisha Gammanpila and Luis Garcia and Shelly Garion and Austin Gilliam and Juan Gomez-Mosquera and Salvador de la Puente Gonz{\'a}lez and Jesse Gorzinski and Ian Gould and Donny Greenberg and Dmitry Grinko and Wen Guan and John A. Gunnels and Mikael Haglund and Isabel Haide and Ikko Hamamura and Vojtech Havlicek and Joe Hellmers and {\L}ukasz Herok and Stefan Hillmich and Hiroshi Horii and Connor Howington and Shaohan Hu and Wei Hu and Haruki Imai and Takashi Imamichi and Kazuaki Ishizaki and Raban Iten and Toshinari Itoko and JamesSeaward and Ali Javadi and Ali Javadi-Abhari and Jessica and Kiran Johns and Tal Kachmann and Naoki Kanazawa and Kang-Bae and Anton Karazeev and Paul Kassebaum and Spencer King and Knabberjoe and Arseny Kovyrshin and Rajiv Krishnakumar and Vivek Krishnan and Kevin Krsulich and Gawel Kus and Ryan LaRose and Rapha{\"e}l Lambert and Joe Latone and Scott Lawrence and Dennis Liu and Peng Liu and Yunho Maeng and Aleksei Malyshev and Jakub Marecek and Manoel Marques and Dolph Mathews and Atsushi Matsuo and Douglas T. McClure and Cameron McGarry and David McKay and Dan McPherson and Srujan Meesala and Martin Mevissen and Antonio Mezzacapo and Rohit Midha and Zlatko Minev and Abby Mitchell and Nikolaj Moll and Michael Duane Mooring and Renier Morales and Niall Moran and MrF and Prakash Murali and Jan M{\"u}ggenburg and David Nadlinger and Ken Nakanishi and Giacomo Nannicini and Paul Nation and Edwin Navarro and Yehuda Naveh and Scott Wyman Neagle and Patrick Neuweiler and Pradeep Niroula and Hassi Norlen and Lee James O'Riordan and Oluwatobi Ogunbayo and Pauline Ollitrault and Steven Oud and Dan Padilha and Hanhee Paik and Simone Perriello and Anna Phan and Francesco Piro and Marco Pistoia and Alejandro Pozas-iKerstjens and Viktor Prutyanov and Daniel Puzzuoli and Jes{\'u}s P{\'e}rez and Quintiii and Rudy Raymond and Rafael Mart{\'\i}n-Cuevas Redondo and Max Reuter and Julia Rice and Diego M. Rodr{\'\i}guez and RohithKarur and Max Rossmannek and Mingi Ryu and Tharrmashastha SAPV and SamFerracin and Martin Sandberg and Hayk Sargsyan and Ninad Sathaye and Bruno Schmitt and Chris Schnabel and Zachary Schoenfeld and Travis L. Scholten and Eddie Schoute and Joachim Schwarm and Ismael Faro Sertage and Kanav Setia and Nathan Shammah and Yunong Shi and Adenilton Silva and Andrea Simonetto and Nick Singstock and Yukio Siraichi and Iskandar Sitdikov and Seyon Sivarajah and Magnus Berg Sletfjerding and John A. Smolin and Mathias Soeken and Igor Olegovich Sokolov and SooluThomas and Dominik Steenken and Matt Stypulkoski and Jack Suen and Shaojun Sun and Kevin J. Sung and Hitomi Takahashi and Ivano Tavernelli and Charles Taylor and Pete Taylour and Soolu Thomas and Mathieu Tillet and Maddy Tod and Enrique de la Torre and Kenso Trabing and Matthew Treinish and TrishaPe and Wes Turner and Yotam Vaknin and Carmen Recio Valcarce and Francois Varchon and Almudena Carrera Vazquez and Desiree Vogt-Lee and Christophe Vuillot and James Weaver and Rafal Wieczorek and Jonathan A. Wildstrom and Robert Wille and Erick Winston and Jack J. Woehr and Stefan Woerner and Ryan Woo and Christopher J. Wood and Ryan Wood and Stephen Wood and Steve Wood and James Wootton and Daniyar Yeralin and Richard Young and Jessie Yu and Christopher Zachow and Laura Zdanski and Christa Zoufal and Zoufalc and a-matsuo and adekusar-drl and azulehner and bcamorrison and brandhsn and chlorophyll-zz and dan1pal and dime10 and drholmie and elfrocampeador and faisaldebouni and fanizzamarco and gadial and gruu and jliu45 and kanejess and klinvill and kurarrr and lerongil and ma5x and merav-aharoni and michelle4654 and ordmoj and sethmerkel and strickroman and sumitpuri and tigerjack and toural and vvilpas and welien and willhbang and yang.luh and yelojakit and yotamvakninibm},
 doi = {10.5281/zenodo.2562110},
 title = {Qiskit: An Open-source Framework for Quantum Computing},
 year = {2019}
}

@article{qml0,
 abstract = {In this paper, we will discuss a formal link between neural networks and quantum computing. For that purpose we will present a simple model for the description of the neural network by forming sub-graphs of the whole network with the same or a similar state. We will describe the interaction between these areas by closed loops, the feedback loops. The change of the graph is given by the deformations of the loops. This fact can be mathematically formalized by the fundamental group of the graph. Furthermore the neuron has two basic states |0〉 (ground state) and |1〉 (excited state). The whole state of an area of neurons is the linear combination of the two basic state with complex coefficients representing the signals (with 3 Parameters: amplitude, frequency and phase) along the neurons. If something changed in this area, we need a transformation which will preserve this general form of a state (mathematically, this transformation must be an element of the group S L(2; C)). The same argumentation must be true for the feedback loops, i.e. a general transformation of states along the feedback loops is an assignment of this loop to an element of the transformation group. Then it can be shown that the set of all signals forms a manifold (character variety) and all properties of the network must be encoded in this manifold. In the paper, we will discuss how to interpret learning and intuition in this model. Using the Morgan-Shalen compactification, the limit for signals with large amplitude can be analyzed by using quasi-Fuchsian groups as represented by dessins d’enfants (graphs to analyze Riemannian surfaces). As shown by Planat and collaborators, these dessins d’enfants are a direct bridge to (topological) quantum computing with permutation groups. The normalization of the signal reduces to the group S U(2) and the whole model to a quantum network. Then we have a direct connection to quantum circuits. This network can be transformed into operations on tensor networks. Formally we will obtain a link between machine learning and Quantum computing.},
 author = {{Asselmeyer-Maluga, Torsten}},
 optdoi = {10.1051/epjconf/201919800014},
 journal = {EPJ Web Conf.},
 pages = {14},
 title = {Quantum computing and the brain: quantum nets, dessins d\'{}enfants and neural networks},
 opturl = {https://doi.org/10.1051/epjconf/201919800014},
 volume = {198},
 year = {2019}
}

@article{qml1,
 abstract = {In this paper, we propose a simple neural net that requires only O(n log_2k) number of qubits and O(nk) quantum gates: Here, N is the number of input parameters, and k is the number of weights applied to these parameters in the proposed neural net. We describe the network in terms of a quantum circuit, and then draw its equivalent classical neural net which involves O(k^n) nodes in the hidden layer. Then, we show that the network uses a periodic activation function of cosine values of the linear combinations of the inputs and weights. The backpropagation is described through the gradient descent, and then iris and breast cancer datasets are used for the simulations. The numerical results indicate the network can be used in machine learning problems and it may provide exponential speedup over the same structured classical neural net.},
 author = {A. {Daskin}},
 journal = {2018 IEEE International Conference on Systems, Man, and Cybernetics},
 optdoi = {10.1109/SMC.2018.00491},
 issn = {1062-922X},
 keywords = {backpropagation;computational complexity;gradient methods;neural nets;quantum gates;quantum gates;cosine values;gradient descent;machine learning problems;equivalent classical neural net;quantum circuit;input parameters;qubits;periodic activation function;simple quantum neural net;Qubit;Logic gates;Biological neural networks;Machine learning;Computational modeling;quantum machine learning;quantum neural networks},
 month = {Oct},
 number = {},
 pages = {2887-2891},
 title = {A Simple Quantum Neural Net with a Periodic Activation Function},
 volume = {},
 year = {2018}
}

@article{qml2,
 abstract = {We use a quantum annealing D-Wave 2X computer to obtain solutions to NP-hard sparse coding problems. To reduce the dimensionality of the sparse coding problem to fit on the quantum D-Wave 2X hardware, we passed downsampled MNIST images through a bottleneck autoencoder. To establish a benchmark for classification performance on this reduced dimensional data set, we used an AlexNet-like architecture implemented in TensorFlow, obtaining a classification score of 94.54±0.7\%. As a control, we showed that the same AlexNet-like architecture produced near-state-of-the-art classification performance (∼99\%) on the original MNIST images. To obtain a set of optimized features for inferring sparse representations of the reduced dimensional MNIST dataset, we imprinted on a random set of 47 image patches followed by an off-line unsupervised learning algorithm using stochastic gradient descent to optimize for sparse coding. Our single-layer of sparse coding matched the stride and patch size of the first convolutional layer of the AlexNet-like deep neural network and contained 47 fully-connected features, 47 being the maximum number of dictionary elements that could be embedded onto the D-Wave 2X hardware. Recent work suggests that the optimal level of sparsity corresponds to a critical value of the trade-off parameter associated with a putative second order phase transition, an observation supported by a free energy analysis of D-Wave energy states. When the sparse representations inferred by the D-Wave 2X were passed to a linear support vector machine, we obtained a classification score of 95.68\%. Thus, on this problem, we find that a single-layer of quantum inference is able to outperform a standard deep neural network architecture.},
 author = {Nguyen, Nga T.T. and Kenyon, Garrett T.},
 isbn = {9781538691700},
 journal = {2018 IEEE International Conference on Rebooting Computing},
 month = {Nov},
 optdoi = {10.1109/icrc.2018.8638596},
 publisher = {IEEE},
 title = {Image Classification Using Quantum Inference on the D-Wave 2X},
 opturl = {http://dx.doi.org/10.1109/ICRC.2018.8638596},
 pages = {2887-2891},
 year = {2018}
}

@article{radovic2018,
 abstract = {Our knowledge of the fundamental particles of nature and their interactions is summarized by the standard model of particle physics. Advancing our understanding in this field has required experiments that operate at ever higher energies and intensities, which produce extremely large and information-rich data samples. The use of machine-learning techniques is revolutionizing how we interpret these data samples, greatly increasing the discovery potential of present and future experiments. Here we summarize the challenges and opportunities that come with the use of machine learning at the frontiers of particle physics.},
 author = {Radovic, Alexander
and Williams, Mike
and Rousseau, David
and Kagan, Michael
and Bonacorsi, Daniele
and Himmel, Alexander
and Aurisano, Adam
and Terao, Kazuhiro
and Wongjirad, Taritree},
 optdoi = {10.1038/s41586-018-0361-2},
 issn = {1476-4687},
 journal = {Nature},
 number = {7716},
 pages = {41-48},
 title = {Machine learning at the energy and intensity frontiers of particle physics},
 opturl = {https://doi.org/10.1038/s41586-018-0361-2},
 volume = {560},
 year = {2018}
}

@article{rebentrost2014,
 author = {Patrick Rebentrost and Masoud Mohseni and Seth Lloyd},
 optdoi = {10.1103/physrevlett.113.130503},
 journal = {Physical Review Letters},
 month = {sep},
 number = {13},
 publisher = {American Physical Society ({APS})},
 title = {Quantum Support Vector Machine for Big Data Classification},
 volume = {113},
 pages = {130503},
 year = {2014}
}

@article{rebentrost2018,
 author = {Rebentrost, Patrick and Bromley, Thomas R. and Weedbrook, Christian and Lloyd, Seth},
 optdoi = {10.1103/PhysRevA.98.042308},
 issue = {4},
 journal = {Phys. Rev. A},
 month = {Oct},
 numpages = {11},
 pages = {042308},
 publisher = {American Physical Society},
 title = {Quantum Hopfield neural network},
 opturl = {https://link.aps.org/doi/10.1103/PhysRevA.98.042308},
 volume = {98},
 year = {2018}
}

@article{liao2021quadratic,
 author = {Liao, Pengcheng and Sanders, Barry C and Byrnes, Tim},
 issue = {4},
 journal = {Phys. Rev. A},
 month = {Oct},
 pages = {062412},
 publisher = {American Physical Society},
 title = {Quadratic quantum speedup for perceptron training},
 volume = {110},
 year = {2024}
}


% inproceedings
@article{santana2017,
 author = {Alessandra Santana and Alessandra Morais and Marcos G. Quiles},
 journal = {2017 International Joint Conference on Neural Networks ({IJCNN})},
 optdoi = {10.1109/ijcnn.2017.7966174},
 month = {may},
 publisher = {{IEEE}},
 title = {An alternative approach for binary and categorical self-organizing maps},
 opturl = {https://doi.org/10.1109%2Fijcnn.2017.7966174},
 pages = {2604-2610},
 year = {2017}
}

@article{schuld2014,
 author = {Maria Schuld and Ilya Sinayskiy and Francesco Petruccione},
 optdoi = {10.1080/00107514.2014.964942},
 journal = {Contemporary Physics},
 month = {oct},
 number = {2},
 pages = {172--185},
 publisher = {Informa {UK} Limited},
 title = {An introduction to quantum machine learning},
 volume = {56},
 year = {2014}
}

@article{schuld2014b,
 author = {Maria Schuld and Ilya Sinayskiy and Francesco Petruccione},
 optdoi = {10.1007/s11128-014-0809-8},
 journal = {Quantum Information Processing},
 month = {aug},
 number = {11},
 pages = {2567--2586},
 publisher = {Springer Science and Business Media {LLC}},
 title = {The quest for a Quantum Neural Network},
 volume = {13},
 year = {2014}
}

@book{schwab2017,
 address = {Redfern, New South Wales},
 author = {Schwab, Klaus},
 publisher = {Currency Press},
 title = {The Fourth Industrial Revolution},
 year = {2017}
}

@article{solan2001,
 author = {Zach Solan and Eytan Ruppin},
 optdoi = {10.1162/089892901564144},
 journal = {Journal of Cognitive Neuroscience},
 month = {jan},
 number = {1},
 pages = {18--30},
 publisher = {{MIT} Press - Journals},
 title = {Similarity in Perception: A Window to Brain Organization},
 volume = {13},
 year = {2001}
}

@article{sze2017,
 author = {Vivienne Sze and Yu-Hsin Chen and Tien-Ju Yang and Joel S. Emer},
 optdoi = {10.1109/jproc.2017.2761740},
 journal = {Proceedings of the {IEEE}},
 month = {dec},
 number = {12},
 pages = {2295--2329},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Efficient Processing of Deep Neural Networks: A Tutorial and Survey},
 volume = {105},
 year = {2017}
}


@article{mohseni2023deep,
  title={Deep recurrent networks predicting the gap evolution in adiabatic quantum computing},
  author={Mohseni, Naeimeh and Navarrete-Benlloch, Carlos and Byrnes, Tim and Marquardt, Florian},
  journal={Quantum},
  volume={7},
  pages={1039},
  year={2023},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@article{mohseni2024deep,
  title={Deep learning of many-body observables and quantum information scrambling},
  author={Mohseni, Naeimeh and Shi, Junheng and Byrnes, Tim and Hartmann, Michael J},
  journal={Quantum},
  volume={8},
  pages={1417},
  year={2024},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}


@article{tacchino2019,
 author = {Francesco Tacchino and Panagiotis Barkoutsos and Chiara Macchiavello and Ivano Tavernelli and Dario Gerace and Daniele Bajoni},
 journal = {arXiv: 1912.12486},
 title = {Quantum implementation of an artificial feed-forward neural network},
 year = {2019}
}

@article{trugenberger2001,
 author = {C. A. Trugenberger},
 optdoi = {10.1103/physrevlett.87.067901},
 journal = {Physical Review Letters},
 month = {jul},
 number = {6},
 publisher = {American Physical Society ({APS})},
 title = {Probabilistic Quantum Memories},
 volume = {87},
 pages = {067901},
 year = {2001}
}

@article{tyrsa2017,
 abstract = {Deep learning is recently showing outstanding results for solving a wide variety of robotic tasks in the areas of perception, planning, localization, and control. Its excellent capabilities for learning representations from the complex data acquired in real environments make it extremely suitable for many kinds of autonomous robotic applications. In parallel, Unmanned Aerial Vehicles (UAVs) are currently being extensively applied for several types of civilian tasks in applications going from security, surveillance, and disaster rescue to parcel delivery or warehouse management. In this paper, a thorough review has been performed on recent reported uses and applications of deep learning for UAVs, including the most relevant developments as well as their performances and limitations. In addition, a detailed explanation of the main deep learning techniques is provided. We conclude with a description of the main challenges for the application of deep learning for UAV-based solutions.},
 author = {Tyrsa, Vera
and Carrio, Adrian
and Sampedro, Carlos
and Rodriguez-Ramos, Alejandro
and Campoy, Pascual},
 journal = {Journal of Sensors},
 key = {},
 note = {},
 number = {},
 pages = {3296874},
 title = {A Review of Deep Learning Methods and Applications for Unmanned Aerial Vehicles},
 opturl = {https://doi.org/10.1155/2017/3296874},
 volume = {2017},
 year = {2017}
}

@book{nielsen2010quantum,
  title={Quantum computation and quantum information},
  author={Nielsen, Michael A and Chuang, Isaac L},
  year={2010},
  publisher={Cambridge university press}
}

@book{byrnes2021quantum,
  title={Quantum atom optics: Theory and applications to quantum technology},
  author={Byrnes, Tim and Ilo-Okeke, Ebubechukwu O},
  year={2021},
  publisher={Cambridge university press}
}

@article{verdon2019,
 author = {Guillaume Verdon and Trevor McCourt and Enxhell Luzhnica and Vikash Singh and Stefan Leichenauer and Jack Hidary},
 journal = {arXiv: 1909.12264},
 title = {Quantum Graph Neural Networks},
 year = {2019}
}

@article{vesanto2000,
 author = {J. Vesanto and E. Alhoniemi},
 optdoi = {10.1109/72.846731},
 journal = {{IEEE} Transactions on Neural Networks},
 month = {may},
 number = {3},
 pages = {586--600},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Clustering of the self-organizing map},
 volume = {11},
 year = {2000}
}

@article{vilibic2016,
 abstract = {An ocean surface currents forecasting system, based on a Self-Organizing Maps (SOM) neural network algorithm, high-frequency (HF) ocean radar measurements and numerical weather prediction (NWP) products, has been developed for a coastal area of the northern Adriatic and compared with operational ROMS-derived surface currents. The two systems differ significantly in architecture and algorithms, being based on either unsupervised learning techniques or ocean physics. To compare performance of the two methods, their forecasting skills were tested on independent datasets. The SOM-based forecasting system has a slightly better forecasting skill, especially during strong wind conditions, with potential for further improvement when data sets of higher quality and longer duration are used for training.},
 author = {Vilibic, Ivica
and Sepic, Jadranka
and Mihanovic, Hrvoje
and Kalinic, Hrvoje
and Cosoli, Simone
and Janekovic, Ivica
and Zagar, Nedjeljka
and Jesenko, Blaz
and Tudor, Martina
and Dadic, Vlado
and Ivankovic, Damir},
 optdoi = {10.1038/srep22924},
 issn = {2045-2322},
 journal = {Scientific Reports},
 number = {1},
 pages = {22924},
 title = {Self-Organizing Maps-based ocean currents forecasting system},
 opturl = {https://doi.org/10.1038/srep22924},
 volume = {6},
 year = {2016}
}

@article{vinci2019,
 author = {Walter Vinci and Lorenzo Buffoni and Hossein Sadeghi and Amir Khoshaman and Evgeny Andriyash and Mohammad H. Amin},
 journal = {arXiv: 1912.02119},
 title = {A Path Towards Quantum Advantage in Training Deep Generative Models with Quantum Annealers},
 year = {2019}
}

@article{wang2018,
 author = {Zhihui Wang and Stuart Hadfield and Zhang Jiang and Eleanor G. Rieffel},
 optdoi = {10.1103/physreva.97.022304},
 journal = {Physical Review A},
 month = {feb},
 number = {2},
 publisher = {American Physical Society ({APS})},
 title = {Quantum approximate optimization algorithm for {MaxCut}: A fermionic view},
 volume = {97},
 pages = {022304},
 year = {2018}
}

@article{wecker2016,
 author = {Dave Wecker and Matthew B. Hastings and Matthias Troyer},
 optdoi = {10.1103/physreva.94.022309},
 journal = {Physical Review A},
 month = {aug},
 number = {2},
 publisher = {American Physical Society ({APS})},
 title = {Training a quantum optimizer},
 volume = {94},
 pages = {022309},
 year = {2016}
}

@inproceedings{weikang2016,
  author = {Rui, Weikang
    and Xing, Kai
    and Jia, Yawei},
  editor = {Lehner, Franz
    and Fteimi, Nora},
  title = {BOWL: Bag of Word Clusters Text Representation Using Word Embeddings},
  booktitle = {Knowledge Science, Engineering and Management},
  year = {2016},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {3--14},
  abstract = {The text representation is fundamental for text mining and information retrieval. The Bag Of Words (BOW) and its variants (e.g. TF-IDF) are very basic text representation methods. Although the BOW and TF-IDF are simple and perform well in tasks like classification and clustering, its representation efficiency is extremely low. Besides, word level semantic similarity is not captured which results failing to capture text level similarity in many situations. In this paper, we propose a straightforward Bag Of Word cLusters (BOWL) representation for texts in a higher level, much lower dimensional space. We exploit the word embeddings to group semantically close words and consider them as a whole. The word embeddings are trained on a large corpus and incorporate extensive knowledge. We demonstrate on three benchmark datasets and two tasks, that BOWL representation shows significant advantages in terms of representation accuracy and efficiency.},
  isbn = {978-3-319-47650-6}
}

@article{wiebe2012,
 author = {Nathan Wiebe and Daniel Braun and Seth Lloyd},
 optdoi = {10.1103/physrevlett.109.050505},
 journal = {Physical Review Letters},
 month = {aug},
 number = {5},
 publisher = {American Physical Society ({APS})},
 title = {Quantum Algorithm for Data Fitting},
 volume = {109},
 pages = {050505},
 year = {2012}
}

@article{zhao2019,
 author = {Zhikuan Zhao and Alejandro Pozas-Kerstjens and Patrick Rebentrost and Peter Wittek},
 optdoi = {10.1007/s42484-019-00004-7},
 journal = {Quantum Machine Intelligence},
 month = {may},
 number = {1-2},
 pages = {41--51},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Bayesian deep learning on a quantum computer},
 volume = {1},
 year = {2019}
}

@article{zhu2018,
 author = {Daqi Zhu and Xiang Cao and Bing Sun and Chaomin Luo},
 optdoi = {10.1109/tcds.2017.2727678},
 journal = {{IEEE} Transactions on Cognitive and Developmental Systems},
 month = {jun},
 number = {2},
 pages = {304--313},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Biologically Inspired Self-Organizing Map Applied to Task Assignment and Path Planning of an {AUV} System},
 volume = {10},
 year = {2018}
}

@Article{byrnes2018,
  author    = {Tim Byrnes and Gary Forster and Louis Tessler},
  title     = {Generalized Grover's Algorithm for Multiple Phase Inversion States},
  journal   = {Physical Review Letters},
  year      = {2018},
  volume    = {120},
  pages     = {060501},
  publisher = {American Physical Society ({APS})},
}

@Article{preskill2018,
  author    = {John Preskill},
  title     = {Quantum Computing in the {NISQ} era and beyond},
  journal   = {Quantum},
  year      = {2018},
  volume    = {2},
  pages     = {79},
  month     = {aug},
  optdoi       = {10.22331/q-2018-08-06-79},
  publisher = {Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
}
